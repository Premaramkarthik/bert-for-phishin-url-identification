{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install evaluate -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:47:08.338072Z","iopub.execute_input":"2025-07-16T17:47:08.338374Z","iopub.status.idle":"2025-07-16T17:47:12.949494Z","shell.execute_reply.started":"2025-07-16T17:47:08.338352Z","shell.execute_reply":"2025-07-16T17:47:12.948737Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import DatasetDict, Dataset, load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification,TrainingArguments, Trainer\n\nimport evaluate\nimport numpy as np\nfrom transformers import DataCollatorWithPadding\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:47:38.537800Z","iopub.execute_input":"2025-07-16T17:47:38.538693Z","iopub.status.idle":"2025-07-16T17:47:38.543381Z","shell.execute_reply.started":"2025-07-16T17:47:38.538661Z","shell.execute_reply":"2025-07-16T17:47:38.542614Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\ndataset_dict = load_dataset(\"shawhin/phishing-site-classification\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:47:39.661879Z","iopub.execute_input":"2025-07-16T17:47:39.662157Z","iopub.status.idle":"2025-07-16T17:47:42.427365Z","shell.execute_reply.started":"2025-07-16T17:47:39.662131Z","shell.execute_reply":"2025-07-16T17:47:42.426720Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c47661faff2541e89b99684ecc89117c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/98.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bfffb6299684686849da5c8ba1138a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/21.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ec4f23aab3f4fc8a6eb1314bca8c3f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/24.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7cc037e3b184c83918e969ca262d419"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7da064ab2be044ad9947cceb73577fc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c76c54afca3b4c8287487d9c888fe95c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e5622498ca04a218964b947fbee72a0"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"model_path = 'google-bert/bert-base-uncased'\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\nid2label = {0: 'Safe', 1: 'Not Safe'}\nlabel2id = {'Safe': 0, 'Not Safe': 1}\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path,\n                                                          num_labels = 2,\n                                                          id2label = id2label,\n                                                          label2id = label2id)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:57:06.915979Z","iopub.execute_input":"2025-07-16T17:57:06.916311Z","iopub.status.idle":"2025-07-16T17:57:10.506761Z","shell.execute_reply.started":"2025-07-16T17:57:06.916281Z","shell.execute_reply":"2025-07-16T17:57:10.506185Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a6c5c8592804dab8a0691806edc001e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b533297b92d9479b9fa08e252545f449"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b156214bf23e426a8800e8df455ccca7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55129648940c471a89aa9e56ad546c63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70a5fafd9bb9468dada4ea4b24c0c1a8"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# to freeze all base model parameter\nfor name, param in model.base_model.named_parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:58:18.620910Z","iopub.execute_input":"2025-07-16T17:58:18.621485Z","iopub.status.idle":"2025-07-16T17:58:18.626811Z","shell.execute_reply.started":"2025-07-16T17:58:18.621453Z","shell.execute_reply":"2025-07-16T17:58:18.626029Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# unfreeze base model pooling layers\n\nfor name, param in model.base_model.named_parameters():\n    if 'pooler' in name:\n        param.required_grad = True\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T18:01:18.704397Z","iopub.execute_input":"2025-07-16T18:01:18.704676Z","iopub.status.idle":"2025-07-16T18:01:18.709236Z","shell.execute_reply.started":"2025-07-16T18:01:18.704658Z","shell.execute_reply":"2025-07-16T18:01:18.708505Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### Data preprocessing ","metadata":{}},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples['text'], truncation = True)\n\ntokenized_data = dataset_dict.map(preprocess_function, batched = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T18:04:32.900666Z","iopub.execute_input":"2025-07-16T18:04:32.901394Z","iopub.status.idle":"2025-07-16T18:04:33.127521Z","shell.execute_reply.started":"2025-07-16T18:04:32.901369Z","shell.execute_reply":"2025-07-16T18:04:33.126771Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa87f21b49d94720bbdbb9496d952b9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac70374bba3f4b51836952f6ea56b62b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b136accf89f44e4ca0a0bd5306631a49"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer = tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T18:05:30.445242Z","iopub.execute_input":"2025-07-16T18:05:30.445834Z","iopub.status.idle":"2025-07-16T18:05:30.449361Z","shell.execute_reply.started":"2025-07-16T18:05:30.445811Z","shell.execute_reply":"2025-07-16T18:05:30.448640Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# load metrics\naccuracy = evaluate.load(\"accuracy\")\nauc_score = evaluate.load(\"roc_auc\")\n\ndef compute_metrics(eval_pred):\n    # get predictions\n    predictions, labels = eval_pred\n    \n    # apply softmax to get probabilities\n    probabilities = np.exp(predictions) / np.exp(predictions).sum(-1, \n                                                                 keepdims=True)\n    # use probabilities of the positive class for ROC AUC\n    positive_class_probs = probabilities[:, 1]\n    # compute auc\n    auc = np.round(auc_score.compute(prediction_scores=positive_class_probs, \n                                     references=labels)['roc_auc'],3)\n    \n    # predict most probable class\n    predicted_classes = np.argmax(predictions, axis=1)\n    # compute accuracy\n    acc = np.round(accuracy.compute(predictions=predicted_classes, \n                                     references=labels)['accuracy'],3)\n    \n    return {\"Accuracy\": acc, \"AUC\": auc}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T18:22:00.244073Z","iopub.execute_input":"2025-07-16T18:22:00.244384Z","iopub.status.idle":"2025-07-16T18:22:01.174687Z","shell.execute_reply.started":"2025-07-16T18:22:00.244362Z","shell.execute_reply":"2025-07-16T18:22:01.174139Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import os \nos.makedirs('/kaggle/working/bert-phishing-classifier_teacher', exist_ok = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T18:14:13.698377Z","iopub.execute_input":"2025-07-16T18:14:13.698732Z","iopub.status.idle":"2025-07-16T18:14:13.703766Z","shell.execute_reply.started":"2025-07-16T18:14:13.698701Z","shell.execute_reply":"2025-07-16T18:14:13.702799Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"model.to(\"cuda\")\nprint(next(model.parameters()).device)  # should print: cuda:0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T18:25:52.341661Z","iopub.execute_input":"2025-07-16T18:25:52.342373Z","iopub.status.idle":"2025-07-16T18:25:52.349162Z","shell.execute_reply.started":"2025-07-16T18:25:52.342352Z","shell.execute_reply":"2025-07-16T18:25:52.348524Z"}},"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# hyperparameters\nlr = 2e-4\nbatch_size = 8\nnum_epochs = 10\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/bert-phishing-classifier_teacher\",\n    learning_rate=lr,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    logging_strategy=\"epoch\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    fp16=True,\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:04:35.136963Z","iopub.execute_input":"2025-07-16T19:04:35.137768Z","iopub.status.idle":"2025-07-16T19:04:35.169553Z","shell.execute_reply.started":"2025-07-16T19:04:35.137739Z","shell.execute_reply":"2025-07-16T19:04:35.168858Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"trainer = Trainer(\n    model = model,\n    args = training_args,\n    train_dataset = tokenized_data['train'],\n    eval_dataset = tokenized_data['test'],\n    tokenizer = tokenizer,\n    data_collator = data_collator,\n    compute_metrics = compute_metrics \n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:04:38.705591Z","iopub.execute_input":"2025-07-16T19:04:38.706094Z","iopub.status.idle":"2025-07-16T19:06:09.462715Z","shell.execute_reply.started":"2025-07-16T19:04:38.706063Z","shell.execute_reply":"2025-07-16T19:06:09.462112Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/413075092.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2630' max='2630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2630/2630 01:29, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.671600</td>\n      <td>0.648057</td>\n      <td>0.669000</td>\n      <td>0.707000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.643600</td>\n      <td>0.663293</td>\n      <td>0.591000</td>\n      <td>0.732000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.625400</td>\n      <td>0.617841</td>\n      <td>0.696000</td>\n      <td>0.760000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.612100</td>\n      <td>0.615600</td>\n      <td>0.669000</td>\n      <td>0.776000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.605400</td>\n      <td>0.631665</td>\n      <td>0.620000</td>\n      <td>0.789000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.589300</td>\n      <td>0.602042</td>\n      <td>0.678000</td>\n      <td>0.795000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.581800</td>\n      <td>0.603057</td>\n      <td>0.673000</td>\n      <td>0.791000</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.584400</td>\n      <td>0.585309</td>\n      <td>0.711000</td>\n      <td>0.803000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.580300</td>\n      <td>0.585654</td>\n      <td>0.702000</td>\n      <td>0.806000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.584600</td>\n      <td>0.588955</td>\n      <td>0.691000</td>\n      <td>0.806000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2630, training_loss=0.607849852123188, metrics={'train_runtime': 90.2619, 'train_samples_per_second': 232.656, 'train_steps_per_second': 29.137, 'total_flos': 706603239165360.0, 'train_loss': 0.607849852123188, 'epoch': 10.0})"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"\n# apply model to validation dataset\npredictions = trainer.predict(tokenized_data[\"validation\"])\n\n# Extract the logits and labels from the predictions object\nlogits = predictions.predictions\nlabels = predictions.label_ids\n\n# Use your compute_metrics function\nmetrics = compute_metrics((logits, labels))\nprint(metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:06:22.506186Z","iopub.execute_input":"2025-07-16T19:06:22.506451Z","iopub.status.idle":"2025-07-16T19:06:23.717447Z","shell.execute_reply.started":"2025-07-16T19:06:22.506433Z","shell.execute_reply":"2025-07-16T19:06:23.716657Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"{'Accuracy': 0.742, 'AUC': 0.809}\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"CUDA is not available. Using CPU instead.\")\n    \n# Move your model to the appropriate device\nmodel = model.to(device)\n\n# Tokenize the input string\ninput_text = \"000mclogin.micloud-object-storage-xc-cos-static-web-hosting-qny.s3.us-east.cloud-object-storage.appdomain.cloud\"\ninputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n\n# Perform inference\nwith torch.no_grad():\n    outputs = model(**inputs)\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n\n# Map prediction to label\npredicted_label = model.config.id2label[predictions.item()]\nprint(f\"Predicted label: {predicted_label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T19:10:39.035715Z","iopub.execute_input":"2025-07-16T19:10:39.036352Z","iopub.status.idle":"2025-07-16T19:10:39.059838Z","shell.execute_reply.started":"2025-07-16T19:10:39.036321Z","shell.execute_reply":"2025-07-16T19:10:39.059094Z"}},"outputs":[{"name":"stdout","text":"Using GPU: Tesla P100-PCIE-16GB\nPredicted label: Not Safe\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}